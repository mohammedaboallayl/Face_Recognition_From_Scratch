{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "458a4279"
      },
      "source": [
        "# Face Recognition Project\n",
        "- **Process Steps**\n",
        "    \n",
        "     - **Loading Data** we started making fetch for all directories we have in our dataset and star to make it our shape which is triple shape $( Anchor , Positive , Negative )$ .\n",
        "           \n",
        "         - **Where :**\n",
        "             - **Anchor** is the image for some one in dataset.\n",
        "             - **Positive** is an image of the same person how is in **Anchor**.\n",
        "             - **Negative** is an image for anthor one .\n",
        "               \n",
        "     -**Creating Data Pipeline**   we have used tensorflow pipline for in creasing performance of loading and make some operations like caching for redusing time make patch which is good for learning model\n",
        "     \n",
        "     -**Creating Model**\n",
        "         - **1** we have made our model depending on MobilenetV3\n",
        "         - **2** we added sum layer on top of model\n",
        "     -**Evaluating Result**\n",
        "         we have two man validation metrics .\n",
        "         - **VAL** which show persent of getting good responce between same person $TP/(TP+FP)$\n",
        "         - **FAR** which show the presentage of in correct decitions of diferent persons $ FN/(FN+TN) $\n",
        "     \n",
        "     -**Making Security For Verification**\n",
        "     \n",
        "     ---------------------------------------------------- **End** ---------------------------------------------------------"
      ],
      "id": "458a4279"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb910238",
        "outputId": "c5c429a8-3adc-442c-e588-8588956b70f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import io\n",
        "import seaborn as sns\n",
        "from keras.layers import Dense,Dropout,Input,BatchNormalization,Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import argparse\n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomRotation,RandomFlip,RandomCrop,PreprocessingLayer\n",
        "#import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"drive\")\n",
        "%matplotlib inline"
      ],
      "id": "bb910238"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb2d8bf8"
      },
      "source": [
        "# dataset"
      ],
      "id": "bb2d8bf8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da40b06e"
      },
      "source": [
        "## loading data"
      ],
      "id": "da40b06e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cafcab8"
      },
      "outputs": [],
      "source": [
        "# BaseDatasetPath=\"./Dataset/Extracted Faces/Extracted Faces/\"\n",
        "# TrainUsersDatasetPath=\"./Dataset/Extracted Faces/team/\"\n",
        "# TestUsersDatasetPath=\"./Dataset/Extracted Faces/test/\"\n",
        "BaseDatasetPath=\"./drive/MyDrive/Extracted Faces/Extracted Faces/\"\n",
        "TrainUsersDatasetPath=\"./drive/MyDrive/Extracted Faces/train/\"\n",
        "TestUsersDatasetPath=\"./drive/MyDrive/Extracted Faces/test/\"\n",
        "def DatasetPaths(BaseDatapath,UserDatapath):\n",
        "    Base=os.listdir(BaseDatapath)\n",
        "    User=os.listdir(UserDatapath)\n",
        "    Basefiles=[]\n",
        "    UserFiles=[]\n",
        "    UserLabels=[]\n",
        "    for folder in Base:\n",
        "        for file in os.listdir(BaseDatapath+folder):\n",
        "            Basefiles.append(BaseDatapath+folder+\"/\"+file)\n",
        "    for folder in User:\n",
        "        for file in os.listdir(UserDatapath+folder):\n",
        "            UserFiles.append(file)\n",
        "            UserLabels.append(folder+'/')\n",
        "\n",
        "    return Basefiles,np.array(UserFiles),np.array(UserLabels)"
      ],
      "id": "6cafcab8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40b596ff"
      },
      "outputs": [],
      "source": [
        "Basefiles,UserFiles,UserLabels=DatasetPaths(BaseDatasetPath,TrainUsersDatasetPath)\n",
        "\n",
        "TrainClasses=np.unique(UserLabels)\n",
        "TrainClassesCount=len(TrainClasses)\n",
        "\n",
        "_,TestUserFiles,TestUserLabels=DatasetPaths(BaseDatasetPath,TestUsersDatasetPath)\n",
        "TestClasses=np.unique(TestUserLabels)\n",
        "TestClassesCount=len(TestClasses)"
      ],
      "id": "40b596ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b2e3eb6"
      },
      "source": [
        "## data augmetation"
      ],
      "id": "9b2e3eb6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cce1691d"
      },
      "outputs": [],
      "source": [
        "mask=np.zeros(shape=(224,224,3))\n",
        "mask[:,:,0]=200\n",
        "mask[:,:,1]=100\n",
        "mask[:,:,2]=200\n",
        "mask=tf.cast(mask/255,tf.float32)\n",
        "FliPer=RandomFlip(mode=\"horizontal\",)\n",
        "Rotater=RandomRotation([-0.135,0.135])\n",
        "def PreProcessInput(Image,num):\n",
        "    if num ==0:\n",
        "        Image=FliPer(Image)\n",
        "    elif num==1:\n",
        "        Image= 0.75*Image+0.25*mask\n",
        "    if num<=2:\n",
        "        return Rotater(Image)\n",
        "\n",
        "    else:\n",
        "        return Image"
      ],
      "id": "cce1691d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b29de2cc"
      },
      "source": [
        "## Loading Images Function"
      ],
      "id": "b29de2cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "998db331"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def load_image(Anchor,Positive,Nagative,State):\n",
        "\n",
        "    Anchor=tf.io.read_file(Anchor)\n",
        "    Anchor=tf.image.decode_jpeg(Anchor)\n",
        "    Anchor = tf.cast(Anchor, tf.float32)\n",
        "    Anchor = tf.image.resize(Anchor, [224,224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    ranA=tf.random.uniform(shape=[1],minval=0,maxval=6,dtype=tf.int32)\n",
        "\n",
        "    Positive=tf.io.read_file(Positive)\n",
        "    Positive=tf.image.decode_jpeg(Positive)\n",
        "    Positive = tf.cast(Positive, tf.float32)\n",
        "    Positive = tf.image.resize(Positive, [224,224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    ranB=tf.random.uniform(shape=[1],minval=0,maxval=6,dtype=tf.int32)\n",
        "\n",
        "    Negative=tf.io.read_file(Nagative)\n",
        "    Negative=tf.image.decode_jpeg(Negative)\n",
        "    Negative = tf.cast(Negative, tf.float32)\n",
        "    Negative = tf.image.resize(Negative, [224,224], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    ranN=tf.random.uniform(shape=[1],minval=0,maxval=6,dtype=tf.int32)\n",
        "    if State:\n",
        "        Anchor=PreProcessInput(Anchor/255,ranA)\n",
        "        Positive=PreProcessInput(Positive/255,ranB)\n",
        "        Negative=PreProcessInput(Negative/255,ranN)\n",
        "    else:\n",
        "        Anchor=Anchor/255\n",
        "        Positive=Positive/255\n",
        "        Negative=Negative/255\n",
        "\n",
        "    return (Anchor,Positive,Negative)"
      ],
      "id": "998db331"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e528c327"
      },
      "outputs": [],
      "source": [
        "def DatasetTripletsGenerator(State):\n",
        "    if State:\n",
        "        ImagesName=UserFiles\n",
        "        ImagesLabel=UserLabels\n",
        "        ClassesCount=TrainClassesCount\n",
        "        Classes=TrainClasses\n",
        "        UserPath=TrainUsersDatasetPath\n",
        "    else:\n",
        "        ImagesName=TestUserFiles\n",
        "        ImagesLabel=TestUserLabels\n",
        "        ClassesCount=TestClassesCount\n",
        "        Classes=TestClasses\n",
        "        UserPath=TestUsersDatasetPath\n",
        "\n",
        "\n",
        "    for i in range(ClassesCount):\n",
        "        class_=Classes[i]\n",
        "        files=ImagesName[ImagesLabel==class_]\n",
        "        files_num=len(files)\n",
        "        for index in range(files_num-1):\n",
        "            for j in range(index+1,files_num):\n",
        "                ancore=UserPath+class_+files[index]\n",
        "                positive=UserPath+class_+files[j]\n",
        "                neg_folder=class_\n",
        "                while neg_folder== class_:\n",
        "                    neg_folder=np.random.choice(Classes)\n",
        "                negative=UserPath+neg_folder+np.random.choice(ImagesName[ImagesLabel==neg_folder])\n",
        "                negative1=np.random.choice(Basefiles)\n",
        "                if np.random.randint(0,high=2)==1:\n",
        "                    negative=negative1\n",
        "                yield ancore,positive,negative,State"
      ],
      "id": "e528c327"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f337c2a"
      },
      "outputs": [],
      "source": [
        "TrainData=tf.data.Dataset.from_generator(DatasetTripletsGenerator,args=[True],output_types=(tf.string,tf.string,tf.string,tf.bool),output_shapes=((),(),(),()),name=\"DataLoaderPipeline\")\n",
        "TrainData=TrainData.map(load_image)\n",
        "TrainData=TrainData.batch(20).shuffle(buffer_size=100)\n",
        "# TrainData=TrainData.prefetch(buffer_size=1)\n",
        "# data=data.cache()\n",
        "TestData=tf.data.Dataset.from_generator(DatasetTripletsGenerator,args=[False],output_types=(tf.string,tf.string,tf.string,tf.bool),output_shapes=((),(),(),()),name=\"DataLoaderPipeline\")\n",
        "TestData=TestData.map(load_image).batch(20)"
      ],
      "id": "0f337c2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eff0fdf"
      },
      "outputs": [],
      "source": [
        "for ancore,positive,negative in TrainData.take(1):\n",
        "    fig,(ax1,ax2,ax3)=plt.subplots(1,3,sharex=True,sharey=True)\n",
        "    ax1.imshow(ancore[0])\n",
        "    ax2.imshow(positive[0])\n",
        "    ax3.imshow(negative[0])"
      ],
      "id": "1eff0fdf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23e4a13b"
      },
      "source": [
        "# Model"
      ],
      "id": "23e4a13b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00809c12"
      },
      "outputs": [],
      "source": [
        "class DistanceLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self,anchor,positive,negative):\n",
        "        dis_ap=tf.reduce_sum(tf.square(anchor - positive), 1)  ## distance between anchor and positive\n",
        "        dis_an=tf.reduce_sum(tf.square(anchor - negative), 1)   ## distance between anchor and negative\n",
        "        return  dis_ap , dis_an"
      ],
      "id": "00809c12"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04717428"
      },
      "outputs": [],
      "source": [
        "def GetEncoder():\n",
        "#     /drive/MyDrive/Model/\n",
        "    return tf.keras.models.load_model(\"./drive/MyDrive/liteFaceRecognitionModel/FaceModelV5\")\n",
        "def SiameseNetwork(inputshape=(224,224,3)):\n",
        "    An_input=Input(shape=inputshape)\n",
        "\n",
        "    Po_input=Input(shape=inputshape)\n",
        "\n",
        "    Ne_input=Input(shape=inputshape)\n",
        "\n",
        "    encoder=GetEncoder()\n",
        "\n",
        "    An_embeding=encoder(An_input)\n",
        "    Po_embeding=encoder(Po_input)\n",
        "    Ne_embeding=encoder(Ne_input)\n",
        "\n",
        "\n",
        "    distanc=DistanceLayer()(An_embeding,Po_embeding,Ne_embeding) #return distance between (A and B) and (A and N)\n",
        "\n",
        "    return Model(inputs=[An_input,Po_input,Ne_input],outputs=distanc)"
      ],
      "id": "04717428"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f62b5bf",
        "outputId": "3e9938b0-5534-4ad6-f9cc-ae0c33d0335d",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "siames_net=SiameseNetwork()"
      ],
      "id": "4f62b5bf"
    },
    {
      "cell_type": "code",
      "source": [
        "siames_net.layers[3].layers[0].trainable=False"
      ],
      "metadata": {
        "id": "FmL0sosuYfID"
      },
      "id": "FmL0sosuYfID",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d62db36"
      },
      "outputs": [],
      "source": [
        "class SiamesModel(Model):\n",
        "    def __init__(self,siames_net,DesiredDistance):\n",
        "        super(SiamesModel, self).__init__()\n",
        "\n",
        "        self.Model=siames_net\n",
        "        self.DesiredDistance=DesiredDistance\n",
        "        self.LossTracker=tf.keras.metrics.Mean(name=\"Loss\")\n",
        "\n",
        "        self.VALTracker=tf.keras.metrics.Mean(name=\"VAL\")\n",
        "\n",
        "        self.PmeanTracker=tf.keras.metrics.Mean(name=\"P_mean\")\n",
        "\n",
        "        self.PmaxTracker=tf.keras.metrics.Mean(name=\"P_max\")\n",
        "\n",
        "        self.PstdTracker=tf.keras.metrics.Mean(name=\"P_std\")\n",
        "\n",
        "        self.FARTracker=tf.keras.metrics.Mean(name=\"FAR\")\n",
        "\n",
        "        self.N_meanTracker=tf.keras.metrics.Mean(name=\"N_mean\")\n",
        "\n",
        "        self.NstdTracker=tf.keras.metrics.Mean(name=\"N_std\")\n",
        "        self.NminTracker=tf.keras.metrics.Mean(name=\"N_min\")\n",
        "\n",
        "    def call(self,data):\n",
        "        return self.Model(data)\n",
        "\n",
        "    def train_step(self,data):\n",
        "        with tf.GradientTape() as Tape:\n",
        "            AP_distanc,AN_distance=self.Model(data)\n",
        "            loss=self.TripLoss(AP_distanc,AN_distance)\n",
        "            gradients=Tape.gradient(loss,self.Model.trainable_weights)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.Model.trainable_weights))\n",
        "        self.DistanceEval(AP_distanc,AN_distance)\n",
        "        self.LossTracker.update_state(loss)\n",
        "        return {\"VAL\":self.VALTracker.result(),\n",
        "                \"P_mean\":self.PmeanTracker.result(),\n",
        "                \"P_max\":self.PmaxTracker.result(),\n",
        "                \"P_std\":self.PstdTracker.result(),\n",
        "                \"FAR\":self.FARTracker.result(),\n",
        "                \"N_mean\":self.N_meanTracker.result(),\n",
        "                \"N_min\":self.NminTracker.result(),\n",
        "                \"N_std\":self.NstdTracker.result(),\n",
        "                \"Loss\":self.LossTracker.result()}\n",
        "\n",
        "\n",
        "    def test_step(self, data):\n",
        "        AP_distanc,AN_distance=self.Model(data)\n",
        "        loss=self.TripLoss(AP_distanc,AN_distance)\n",
        "        self.LossTracker.update_state(loss)\n",
        "        self.DistanceEval(AP_distanc,AN_distance)\n",
        "        return {\"VAL\":self.VALTracker.result(),\n",
        "                \"P_mean\":self.PmeanTracker.result(),\n",
        "                \"P_max\":self.PmaxTracker.result(),\n",
        "                \"P_std\":self.PstdTracker.result(),\n",
        "                \"FAR\":self.FARTracker.result(),\n",
        "                \"N_mean\":self.N_meanTracker.result(),\n",
        "                \"N_min\":self.NminTracker.result(),\n",
        "                \"N_std\":self.NstdTracker.result(),\n",
        "                \"Loss\":self.LossTracker.result()}\n",
        "\n",
        "\n",
        "\n",
        "    def TripLoss(self,ap_distance,an_distance):\n",
        "        return tf.reduce_mean(tf.maximum(ap_distance-0.2*self.DesiredDistance,0)+tf.maximum(self.DesiredDistance-an_distance, 0.0))\n",
        "\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.LossTracker,self.VALTracker,self.PmaxTracker,self.PmeanTracker,self.PstdTracker,self.FARTracker,self.N_meanTracker,self.NminTracker,self.NstdTracker]\n",
        "\n",
        "    def DistanceEval(self,P_distance,N_distance):\n",
        "\n",
        "        P_pred,N_pred=self.TDEvaluation(P_distance,N_distance)\n",
        "        PCDCount=tf.size(tf.where(P_pred))\n",
        "\n",
        "        VAL=PCDCount/tf.size(P_pred)\n",
        "        self.VALTracker.update_state(VAL)\n",
        "\n",
        "        NCDcount=tf.size(tf.where(N_pred))\n",
        "        FAR=1-(NCDcount/tf.size(P_pred))\n",
        "        self.FARTracker.update_state(FAR)\n",
        "        P_mean=tf.reduce_mean(P_distance)\n",
        "        self.PmeanTracker.update_state(P_mean)\n",
        "        N_mean=tf.reduce_mean(N_distance)\n",
        "        self.N_meanTracker.update_state(N_mean)\n",
        "        P_std=tf.math.reduce_std(P_distance)\n",
        "        self.PstdTracker.update_state(P_std)\n",
        "        N_std=tf.math.reduce_std(N_distance)\n",
        "        self.NstdTracker.update_state(N_std)\n",
        "        P_max=tf.reduce_max(P_distance)\n",
        "        self.PmaxTracker.update_state(P_max)\n",
        "        N_min=tf.reduce_min(N_distance)\n",
        "        self.NminTracker.update_state(N_min)\n",
        "\n",
        "    def TDEvaluation(self,P_distance,N_distance):\n",
        "        return tf.cast(P_distance<=self.DesiredDistance,dtype=tf.int8),tf.cast(N_distance>self.DesiredDistance,dtype=tf.int8)"
      ],
      "id": "5d62db36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3acc85f"
      },
      "outputs": [],
      "source": [
        "DesiredDistance=1\n",
        "Optimizer= Adam(learning_rate=1e-4)\n",
        "Siamesmodel=SiamesModel(siames_net,DesiredDistance)\n",
        "Siamesmodel.compile(optimizer=Adam(1e-4),weighted_metrics=[])"
      ],
      "id": "c3acc85f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6c01166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55f157f-5b60-441c-db9d-3bd90b93dc84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "43/43 [==============================] - 139s 2s/step - VAL: 1.0000 - P_mean: 0.0237 - P_max: 0.0909 - P_std: 0.0222 - FAR: 0.0000e+00 - N_mean: 1.8952 - N_min: 1.5068 - N_std: 0.1509 - Loss: 2.3350e-04 - val_Loss: 0.0026 - val_VAL: 1.0000 - val_P_max: 0.1197 - val_P_mean: 0.0302 - val_P_std: 0.0316 - val_FAR: 0.0250 - val_N_mean: 1.8053 - val_N_min: 1.1383 - val_N_std: 0.2300\n",
            "Epoch 2/2\n",
            "43/43 [==============================] - 136s 2s/step - VAL: 1.0000 - P_mean: 0.0192 - P_max: 0.0774 - P_std: 0.0190 - FAR: 0.0012 - N_mean: 1.9005 - N_min: 1.5267 - N_std: 0.1430 - Loss: 5.1480e-04 - val_Loss: 0.0028 - val_VAL: 1.0000 - val_P_max: 0.1111 - val_P_mean: 0.0292 - val_P_std: 0.0290 - val_FAR: 0.0500 - val_N_mean: 1.8685 - val_N_min: 1.3016 - val_N_std: 0.2173\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a192a2e39a0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "Siamesmodel.fit(TrainData,validation_data=TestData,epochs=2)"
      ],
      "id": "a6c01166"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f673ea2a"
      },
      "source": [
        "# Converting to TFlite"
      ],
      "id": "f673ea2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15dc58c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad5699b-9894-4c21-d070-27a57bac968f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "siames_net.layers[3].save(\"./drive/MyDrive/liteFaceRecognitionModel/FaceModelV5\")"
      ],
      "id": "15dc58c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e958686"
      },
      "outputs": [],
      "source": [
        "\n",
        "converter.optimizations=[tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types=[tf.float16]\n",
        "tflitemodel=converter.convert()"
      ],
      "id": "8e958686"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a16d64b"
      },
      "outputs": [],
      "source": [
        "with open(\"./drive/MyDrive/liteFaceRecognitionModel/FinalFaceModel30Epoce.tflite\",\"wb\") as file:\n",
        "    file.write(tflitemodel)"
      ],
      "id": "3a16d64b"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}