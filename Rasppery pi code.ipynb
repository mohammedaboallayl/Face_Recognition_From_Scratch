{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc36c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install tflite-runtime\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f8168d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c9ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "FacesEmbedding=pd.read_csv(\"FinalEmbedding.csv\",index_col=0)\n",
    "persons=list(FacesEmbedding.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463c243b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aboallil</th>\n",
       "      <th>kabel</th>\n",
       "      <th>mahmoud</th>\n",
       "      <th>shams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aboallil     kabel  mahmoud  shams\n",
       "0  0.000000  0.234469      0.0    0.0\n",
       "1  0.004311  0.000000      0.0    0.0\n",
       "2  0.000000  0.000000      0.0    0.0\n",
       "3  0.000000  0.000000      0.0    0.0\n",
       "4  0.000000  0.000000      0.0    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FacesEmbedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f203c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"./FinalFaceModel30Epoce.tflite\"\n",
    "interpreter=tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details=interpreter.get_input_details()\n",
    "output_detail=interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fa83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MediapipeModelPath=\"./mediapipemodels/face_landmarker.task\"\n",
    "BaseOptions=mp.tasks.BaseOptions\n",
    "FaceLandMarker=mp.tasks.vision.FaceLandmarker\n",
    "FaceLandMarkerOptions=mp.tasks.vision.FaceLandmarkerOptions\n",
    "VisionRunningMode=mp.tasks.vision.RunningMode\n",
    "FaceLandMarkerResult=mp.tasks.vision.FaceLandmarkerResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1566091",
   "metadata": {},
   "outputs": [],
   "source": [
    "options=FaceLandMarkerOptions(base_options=BaseOptions(model_asset_path=MediapipeModelPath),\n",
    "                             running_mode=VisionRunningMode.IMAGE)\n",
    "landmarker= FaceLandMarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d392147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "StreamCapture=cv2.VideoCapture(\"./zz.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1340d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(results,FaceImage,persons):\n",
    "    for res in results.face_landmarks:\n",
    "        \n",
    "        x_=int(res[145].x*frame.shape[1])\n",
    "        y_=int(res[145].y*frame.shape[0])\n",
    "        x2_=int(res[374].x*frame.shape[1])\n",
    "        y2_=int(res[374].y*frame.shape[0])\n",
    "        w=np.sqrt((x_-x2_)**2+(y_-y2_)**2)\n",
    "        W=6.3\n",
    "        f = 840\n",
    "        d = (W * f) / w\n",
    "        x=int(res[356].x*frame.shape[1])\n",
    "        y=int(res[152].y*frame.shape[0])\n",
    "        x2=int(res[162].x*frame.shape[1])\n",
    "        y2=int(res[338].y*frame.shape[0])\n",
    "        if x<FaceImage.shape[1]-10:\n",
    "            x+=10\n",
    "        if y>FaceImage.shape[0]-10:\n",
    "            y+=10\n",
    "        if x2>10:\n",
    "            x2-=10\n",
    "        if y2>10:\n",
    "            y2-=10\n",
    "        \n",
    "        \n",
    "        modelimg=mp_img.numpy_view()[y2:y,x2:x]\n",
    "        FaceImage=cv2.rectangle(np.array(FaceImage),(x,y),(x2,y2),(255,0,0),3)\n",
    "        cv2.putText(FaceImage,f\"distance {d}\",(x2,y), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "        \n",
    "        if modelimg.size<9:\n",
    "            continue\n",
    "        modelimg=cv2.resize(modelimg,(224,224)).astype(np.float32)\n",
    "        modelimg=modelimg/255\n",
    "        \n",
    "        distances=[]\n",
    "        if d>0:\n",
    "            for index,name in enumerate(persons):\n",
    "                interpreter.set_tensor(input_details[0][\"index\"],np.expand_dims(modelimg,axis=0))\n",
    "                interpreter.invoke()\n",
    "                output=interpreter.get_tensor(output_detail[0][\"index\"])[0]\n",
    "                personimpeding=FacesEmbedding[name].values\n",
    "                distance=np.sum(np.power(output-personimpeding,2))\n",
    "                distances.append(distance)\n",
    "            name=persons[np.argmin(distances)]\n",
    "            distance=distances[np.argmin(distances)]\n",
    "            if distance <0.29:\n",
    "#                 modelimg=cv2.putText(modelimg,name+f\"{distance}\",(0,125), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),1)\n",
    "                modelimg=cv2.putText(modelimg,name,(0,125), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),3)\n",
    "                modelimg=cv2.cvtColor(modelimg,cv2.COLOR_RGB2BGR)            \n",
    "                cv2.imshow(name,modelimg)\n",
    "#                 FaceImage=cv2.putText(FaceImage,f\"distance {distance}\",(x2,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "                FaceImage=cv2.putText(FaceImage,f\"name {name}\",(x2,y2), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),3)\n",
    "                FaceImage=cv2.cvtColor(FaceImage,cv2.COLOR_RGB2BGR)\n",
    "                FaceImage=cv2.resize(FaceImage,dsize=(0,0),fx=0.5,fy=0.5)\n",
    "                cv2.imshow(\"FaceImage\",FaceImage)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "#                 FaceImage=cv2.putText(FaceImage,f\"distance {distance}\",(x2,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1)\n",
    "                FaceImage=cv2.putText(FaceImage,f\"name UnKnow\",(x2,y2), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),3)\n",
    "                FaceImage=cv2.cvtColor(FaceImage,cv2.COLOR_RGB2BGR)\n",
    "                FaceImage=cv2.resize(FaceImage,dsize=(0,0),fx=0.5,fy=0.5)\n",
    "                cv2.imshow(\"FaceImage\",FaceImage)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8f4065e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "while StreamCapture.isOpened:\n",
    "\n",
    "#     img=cv2.imread(\"./kl.jpg\")\n",
    "    _,frame=StreamCapture.read()\n",
    "#     frame[2:img.shape[0]+2,5:img.shape[1]+5]=img\n",
    "    frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    mp_img=mp.Image(image_format=mp.ImageFormat.SRGB,data=frame)\n",
    "    result=landmarker.detect(mp_img)\n",
    "    \n",
    "    modelimg=render(result,mp_img.numpy_view(),persons)\n",
    "    \n",
    "    key=cv2.waitKey(1000)\n",
    "    if key ==27:\n",
    "        key=cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ad804cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e356e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
